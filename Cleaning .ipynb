{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"medium_NLP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to build a State-of-the-Art Conversationa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>12</td>\n",
       "      <td>3.7K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/huggingface/how-to-build-a-...</td>\n",
       "      <td>https://medium.com/@Thomwolf?source=tag_archiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smaller, faster, cheaper, lighter: Introducin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>NLP</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/huggingface/distilbert-8cf3...</td>\n",
       "      <td>https://medium.com/@victorsanh?source=tag_arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Como Machine Learning consegue diferenciar het...</td>\n",
       "      <td>O Projeto de Processamento</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucas Sepeda</td>\n",
       "      <td>Turing Talks</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>7</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/turing-talks/como-machine-l...</td>\n",
       "      <td>https://medium.com/@lucassepeda?source=tag_arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Top 10 Best Text Analytics APIs: Watson, Googl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Yasu</td>\n",
       "      <td>Rakuten RapidAPI</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>17</td>\n",
       "      <td>NLP</td>\n",
       "      <td>9</td>\n",
       "      <td>2K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/rakuten-rapidapi/top-10-bes...</td>\n",
       "      <td>https://medium.com/@yasunaka.cho.rakuten?sourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Future of Better Care and Better HealthA Val...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Xenolytix</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>NLP</td>\n",
       "      <td>4</td>\n",
       "      <td>2K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@xenolytix/a-future-of-bett...</td>\n",
       "      <td>https://medium.com/@xenolytix?source=tag_archi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0   How to build a State-of-the-Art Conversationa...   \n",
       "1   Smaller, faster, cheaper, lighter: Introducin...   \n",
       "2  Como Machine Learning consegue diferenciar het...   \n",
       "3  Top 10 Best Text Analytics APIs: Watson, Googl...   \n",
       "4  A Future of Better Care and Better HealthA Val...   \n",
       "\n",
       "                     Subtitle  Image        Author       Publication  Year  \\\n",
       "0                         NaN      1   Thomas Wolf       HuggingFace  2019   \n",
       "1                         NaN      1   Victor Sanh       HuggingFace  2019   \n",
       "2  O Projeto de Processamento      1  Lucas Sepeda      Turing Talks  2020   \n",
       "3                         NaN      1          Yasu  Rakuten RapidAPI  2019   \n",
       "4                         NaN      1     Xenolytix               NaN  2019   \n",
       "\n",
       "   Month  Day  Tag  Reading_Time Claps  Comment  \\\n",
       "0      5    9  NLP            12  3.7K        0   \n",
       "1      8   28  NLP            10  3.1K        0   \n",
       "2      4   19  NLP             7  3.1K        0   \n",
       "3      6   17  NLP             9    2K        0   \n",
       "4      5    8  NLP             4    2K        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://medium.com/huggingface/how-to-build-a-...   \n",
       "1  https://medium.com/huggingface/distilbert-8cf3...   \n",
       "2  https://medium.com/turing-talks/como-machine-l...   \n",
       "3  https://medium.com/rakuten-rapidapi/top-10-bes...   \n",
       "4  https://medium.com/@xenolytix/a-future-of-bett...   \n",
       "\n",
       "                                          Author_url  \n",
       "0  https://medium.com/@Thomwolf?source=tag_archiv...  \n",
       "1  https://medium.com/@victorsanh?source=tag_arch...  \n",
       "2  https://medium.com/@lucassepeda?source=tag_arc...  \n",
       "3  https://medium.com/@yasunaka.cho.rakuten?sourc...  \n",
       "4  https://medium.com/@xenolytix?source=tag_archi...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            215\n",
       "Subtitle        1531\n",
       "Image              0\n",
       "Author             0\n",
       "Publication     1818\n",
       "Year               0\n",
       "Month              0\n",
       "Day                0\n",
       "Tag                0\n",
       "Reading_Time       0\n",
       "Claps              0\n",
       "Comment            0\n",
       "url                0\n",
       "Author_url         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.loc[raw_data['Title'].isnull(),'Title'] = raw_data['Subtitle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            160\n",
       "Subtitle        1531\n",
       "Image              0\n",
       "Author             0\n",
       "Publication     1818\n",
       "Year               0\n",
       "Month              0\n",
       "Day                0\n",
       "Tag                0\n",
       "Reading_Time       0\n",
       "Claps              0\n",
       "Comment            0\n",
       "url                0\n",
       "Author_url         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.loc[raw_data['Title'].isnull(),'Title'] = \"no title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title              0\n",
       "Subtitle        1531\n",
       "Image              0\n",
       "Author             0\n",
       "Publication     1818\n",
       "Year               0\n",
       "Month              0\n",
       "Day                0\n",
       "Tag                0\n",
       "Reading_Time       0\n",
       "Claps              0\n",
       "Comment            0\n",
       "url                0\n",
       "Author_url         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title              0\n",
       "Subtitle           0\n",
       "Image              0\n",
       "Author             0\n",
       "Publication     1818\n",
       "Year               0\n",
       "Month              0\n",
       "Day                0\n",
       "Tag                0\n",
       "Reading_Time       0\n",
       "Claps              0\n",
       "Comment            0\n",
       "url                0\n",
       "Author_url         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.loc[raw_data['Subtitle'].isnull(),'Subtitle'] = \"no subtitle\"\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title           0\n",
       "Subtitle        0\n",
       "Image           0\n",
       "Author          0\n",
       "Publication     0\n",
       "Year            0\n",
       "Month           0\n",
       "Day             0\n",
       "Tag             0\n",
       "Reading_Time    0\n",
       "Claps           0\n",
       "Comment         0\n",
       "url             0\n",
       "Author_url      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.loc[raw_data['Publication'].isnull(),'Publication'] = \"no Publication\"\n",
    "raw_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_predict = raw_data.iloc[:,0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to build a State-of-the-Art Conversationa...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>12</td>\n",
       "      <td>3.7K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smaller, faster, cheaper, lighter: Introducin...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>NLP</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle  Image  \\\n",
       "0   How to build a State-of-the-Art Conversationa...  no subtitle      1   \n",
       "1   Smaller, faster, cheaper, lighter: Introducin...  no subtitle      1   \n",
       "\n",
       "        Author  Publication  Year  Month  Day  Tag  Reading_Time Claps  \\\n",
       "0  Thomas Wolf  HuggingFace  2019      5    9  NLP            12  3.7K   \n",
       "1  Victor Sanh  HuggingFace  2019      8   28  NLP            10  3.1K   \n",
       "\n",
       "   Comment  \n",
       "0        0  \n",
       "1        0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3777.000000</td>\n",
       "      <td>3777.000000</td>\n",
       "      <td>3777.000000</td>\n",
       "      <td>3777.000000</td>\n",
       "      <td>3777.000000</td>\n",
       "      <td>3777.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.879534</td>\n",
       "      <td>2019.393699</td>\n",
       "      <td>6.296267</td>\n",
       "      <td>16.014032</td>\n",
       "      <td>5.688377</td>\n",
       "      <td>0.039185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.325549</td>\n",
       "      <td>0.488634</td>\n",
       "      <td>3.440839</td>\n",
       "      <td>8.754936</td>\n",
       "      <td>4.487513</td>\n",
       "      <td>0.194059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2019.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Image         Year        Month          Day  Reading_Time  \\\n",
       "count  3777.000000  3777.000000  3777.000000  3777.000000   3777.000000   \n",
       "mean      0.879534  2019.393699     6.296267    16.014032      5.688377   \n",
       "std       0.325549     0.488634     3.440839     8.754936      4.487513   \n",
       "min       0.000000  2019.000000     1.000000     1.000000      0.000000   \n",
       "25%       1.000000  2019.000000     3.000000     8.000000      3.000000   \n",
       "50%       1.000000  2019.000000     6.000000    16.000000      5.000000   \n",
       "75%       1.000000  2020.000000     9.000000    24.000000      7.000000   \n",
       "max       1.000000  2020.000000    12.000000    31.000000    140.000000   \n",
       "\n",
       "           Comment  \n",
       "count  3777.000000  \n",
       "mean      0.039185  \n",
       "std       0.194059  \n",
       "min       0.000000  \n",
       "25%       0.000000  \n",
       "50%       0.000000  \n",
       "75%       0.000000  \n",
       "max       1.000000  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_predict.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_chars = [\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
    "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
    "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
    "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in spec_chars:\n",
    "    df_for_predict['Title'] = df_for_predict['Title'].str.replace(char, ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to build a State of the Art Conversationa...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>12</td>\n",
       "      <td>3.7K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smaller  faster  cheaper  lighter  Introducin...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>NLP</td>\n",
       "      <td>10</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle  Image  \\\n",
       "0   How to build a State of the Art Conversationa...  no subtitle      1   \n",
       "1   Smaller  faster  cheaper  lighter  Introducin...  no subtitle      1   \n",
       "\n",
       "        Author  Publication  Year  Month  Day  Tag  Reading_Time Claps  \\\n",
       "0  Thomas Wolf  HuggingFace  2019      5    9  NLP            12  3.7K   \n",
       "1  Victor Sanh  HuggingFace  2019      8   28  NLP            10  3.1K   \n",
       "\n",
       "   Comment  \n",
       "0        0  \n",
       "1        0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_predict['Title'] = df_for_predict['Title'].str.split().str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in spec_chars:\n",
    "    df_for_predict['Subtitle'] = df_for_predict['Subtitle'].str.replace(char, ' ')\n",
    "    \n",
    "df_for_predict['Subtitle'] = df_for_predict['Subtitle'].str.split().str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for char in spec_chars:\n",
    "    df_for_predict['Author'] = df_for_predict['Author'].str.replace(char, ' ')\n",
    "    \n",
    "df_for_predict['Author'] = df_for_predict['Author'].str.split().str.join(\" \")\n",
    "\n",
    "for char in spec_chars:\n",
    "    df_for_predict['Publication'] = df_for_predict['Publication'].str.replace(char, ' ')\n",
    "    \n",
    "df_for_predict['Publication'] = df_for_predict['Publication'].str.split().str.join(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict = {'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', }\n",
    "df_for_predict['Claps'] = df_for_predict['Claps'].replace(repl_dict, regex=True).map(pd.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How to build a State of the Art Conversational...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Thomas Wolf</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>12</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Smaller faster cheaper lighter Introducing Dil...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>Victor Sanh</td>\n",
       "      <td>HuggingFace</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>NLP</td>\n",
       "      <td>10</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle  Image  \\\n",
       "0  How to build a State of the Art Conversational...  no subtitle      1   \n",
       "1  Smaller faster cheaper lighter Introducing Dil...  no subtitle      1   \n",
       "\n",
       "        Author  Publication  Year  Month  Day  Tag  Reading_Time   Claps  \\\n",
       "0  Thomas Wolf  HuggingFace  2019      5    9  NLP            12  3700.0   \n",
       "1  Victor Sanh  HuggingFace  2019      8   28  NLP            10  3100.0   \n",
       "\n",
       "   Comment  \n",
       "0        0  \n",
       "1        0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title            object\n",
       "Subtitle         object\n",
       "Image             int64\n",
       "Author           object\n",
       "Publication      object\n",
       "Year              int64\n",
       "Month             int64\n",
       "Day               int64\n",
       "Tag              object\n",
       "Reading_Time      int64\n",
       "Claps           float64\n",
       "Comment           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_predict.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_for_predict = df_for_predict.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to build a state of the art conversational...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>thomas wolf</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>nlp</td>\n",
       "      <td>12</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smaller faster cheaper lighter introducing dil...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>victor sanh</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>nlp</td>\n",
       "      <td>10</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle Image  \\\n",
       "0  how to build a state of the art conversational...  no subtitle     1   \n",
       "1  smaller faster cheaper lighter introducing dil...  no subtitle     1   \n",
       "\n",
       "        Author  Publication  Year Month Day  Tag Reading_Time   Claps Comment  \n",
       "0  thomas wolf  huggingface  2019     5   9  nlp           12  3700.0       0  \n",
       "1  victor sanh  huggingface  2019     8  28  nlp           10  3100.0       0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-01-01 00:00:00')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_datetime(str(2019),format='%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_for_predict['date'] = pd.to_datetime(clean_df_for_predict[[\"Year\",\"Month\",\"Day\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to build a state of the art conversational...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>thomas wolf</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>nlp</td>\n",
       "      <td>12</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smaller faster cheaper lighter introducing dil...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>victor sanh</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>nlp</td>\n",
       "      <td>10</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle Image  \\\n",
       "0  how to build a state of the art conversational...  no subtitle     1   \n",
       "1  smaller faster cheaper lighter introducing dil...  no subtitle     1   \n",
       "\n",
       "        Author  Publication  Year Month Day  Tag Reading_Time   Claps Comment  \\\n",
       "0  thomas wolf  huggingface  2019     5   9  nlp           12  3700.0       0   \n",
       "1  victor sanh  huggingface  2019     8  28  nlp           10  3100.0       0   \n",
       "\n",
       "        date  \n",
       "0 2019-05-09  \n",
       "1 2019-08-28  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df_for_predict['release_day'] = clean_df_for_predict['date'].dt.day_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>date</th>\n",
       "      <th>release_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to build a state of the art conversational...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>thomas wolf</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>nlp</td>\n",
       "      <td>12</td>\n",
       "      <td>3700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-05-09</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smaller faster cheaper lighter introducing dil...</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>1</td>\n",
       "      <td>victor sanh</td>\n",
       "      <td>huggingface</td>\n",
       "      <td>2019</td>\n",
       "      <td>8</td>\n",
       "      <td>28</td>\n",
       "      <td>nlp</td>\n",
       "      <td>10</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Subtitle Image  \\\n",
       "0  how to build a state of the art conversational...  no subtitle     1   \n",
       "1  smaller faster cheaper lighter introducing dil...  no subtitle     1   \n",
       "\n",
       "        Author  Publication  Year Month Day  Tag Reading_Time   Claps Comment  \\\n",
       "0  thomas wolf  huggingface  2019     5   9  nlp           12  3700.0       0   \n",
       "1  victor sanh  huggingface  2019     8  28  nlp           10  3100.0       0   \n",
       "\n",
       "        date release_day  \n",
       "0 2019-05-09    Thursday  \n",
       "1 2019-08-28   Wednesday  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df_for_predict.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"df_2020_I.csv\")\n",
    "df_2 = pd.read_csv(\"df_2020_II.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1,df_2], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>article_text</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como Machine Learning consegue diferenciar het...</td>\n",
       "      <td>O Projeto de Processamento</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucas Sepeda</td>\n",
       "      <td>Turing Talks</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>7</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/turing-talks/como-machine-l...</td>\n",
       "      <td>https://medium.com/@lucassepeda?source=tag_arc...</td>\n",
       "      <td>['Projeto desenvolvido por: Fernando Matsumoto...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brutal truths that NLP data scientists will no...</td>\n",
       "      <td>Shared by a data scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Wei Hong</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>6</td>\n",
       "      <td>1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/brutal-truths-t...</td>\n",
       "      <td>https://towardsdatascience.com/@lowweihong?sou...</td>\n",
       "      <td>['According to the report by Tractica, the AI-...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>He Made Me Eat off the Floor When I Was Eight</td>\n",
       "      <td>How I retroactively claimed the power of my no</td>\n",
       "      <td>1</td>\n",
       "      <td>Duncan Riach, Ph.D.</td>\n",
       "      <td>Humanity Dawns</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NLP</td>\n",
       "      <td>7</td>\n",
       "      <td>1.7K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/humanity-dawns/the-staggeri...</td>\n",
       "      <td>https://medium.com/@duncanr?source=tag_archive...</td>\n",
       "      <td>['In Some Snapshots from My Shitty Childhood, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using NLP to Detect Fake News</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1</td>\n",
       "      <td>Arjun Mohnot</td>\n",
       "      <td>Noteworthy The Journal Blog</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>NLP</td>\n",
       "      <td>6</td>\n",
       "      <td>1.7K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://blog.usejournal.com/using-nlp-to-detec...</td>\n",
       "      <td>https://blog.usejournal.com/@arjunmohnot?sourc...</td>\n",
       "      <td>['Introduction', 'Nowadays, information can ea...</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Five Cool Python Libraries for Data Science</td>\n",
       "      <td>Handy Python libraries for data science</td>\n",
       "      <td>1</td>\n",
       "      <td>Dhilip Subramanian</td>\n",
       "      <td>Towards AI Multidisciplinary Science Journal</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>4</td>\n",
       "      <td>1.7K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/towards-artificial-intellig...</td>\n",
       "      <td>https://medium.com/@sdhilip?source=tag_archive...</td>\n",
       "      <td>['Python is a best friend for the majority of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Como Machine Learning consegue diferenciar het...   \n",
       "1  Brutal truths that NLP data scientists will no...   \n",
       "2      He Made Me Eat off the Floor When I Was Eight   \n",
       "3                     Using NLP to Detect Fake News    \n",
       "4        Five Cool Python Libraries for Data Science   \n",
       "\n",
       "                                         Subtitle  Image               Author  \\\n",
       "0                      O Projeto de Processamento      1         Lucas Sepeda   \n",
       "1                      Shared by a data scientist      1         Low Wei Hong   \n",
       "2  How I retroactively claimed the power of my no      1  Duncan Riach, Ph.D.   \n",
       "3                                    Introduction      1         Arjun Mohnot   \n",
       "4         Handy Python libraries for data science      1   Dhilip Subramanian   \n",
       "\n",
       "                                    Publication  Year  Month  Day  Tag  \\\n",
       "0                                  Turing Talks  2020      4   19  NLP   \n",
       "1                          Towards Data Science  2020      1   19  NLP   \n",
       "2                                Humanity Dawns  2020      1   30  NLP   \n",
       "3                   Noteworthy The Journal Blog  2020      3   14  NLP   \n",
       "4  Towards AI Multidisciplinary Science Journal  2020      1    9  NLP   \n",
       "\n",
       "   Reading_Time Claps  Comment  \\\n",
       "0             7  3.1K        0   \n",
       "1             6    1K        0   \n",
       "2             7  1.7K        0   \n",
       "3             6  1.7K        0   \n",
       "4             4  1.7K        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://medium.com/turing-talks/como-machine-l...   \n",
       "1  https://towardsdatascience.com/brutal-truths-t...   \n",
       "2  https://medium.com/humanity-dawns/the-staggeri...   \n",
       "3  https://blog.usejournal.com/using-nlp-to-detec...   \n",
       "4  https://medium.com/towards-artificial-intellig...   \n",
       "\n",
       "                                          Author_url  \\\n",
       "0  https://medium.com/@lucassepeda?source=tag_arc...   \n",
       "1  https://towardsdatascience.com/@lowweihong?sou...   \n",
       "2  https://medium.com/@duncanr?source=tag_archive...   \n",
       "3  https://blog.usejournal.com/@arjunmohnot?sourc...   \n",
       "4  https://medium.com/@sdhilip?source=tag_archive...   \n",
       "\n",
       "                                        article_text  no_of_blockquotes  \\\n",
       "0  ['Projeto desenvolvido por: Fernando Matsumoto...                  1   \n",
       "1  ['According to the report by Tractica, the AI-...                  4   \n",
       "2  ['In Some Snapshots from My Shitty Childhood, ...                  0   \n",
       "3  ['Introduction', 'Nowadays, information can ea...                  5   \n",
       "4  ['Python is a best friend for the majority of ...                  0   \n",
       "\n",
       "   no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "0                 25                  17                  16   \n",
       "1                 10                   1                   4   \n",
       "2                  2                   0                   1   \n",
       "3                 11                   5                  15   \n",
       "4                 26                   0                   8   \n",
       "\n",
       "   no_of_code_chunks  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                 15  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>article_text</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>RAJESH SAHU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@martinpella/how-to-use-pre...</td>\n",
       "      <td>https://medium.com/@rajeshsahuise?source=tag_a...</td>\n",
       "      <td>['â€œFor decades, machine learning approaches ta...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>559</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Thomas Packer, Ph.D.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/modern-nlp/on-variety-of-en...</td>\n",
       "      <td>https://medium.com/@thomaspacker?source=tag_ar...</td>\n",
       "      <td>['Encoding text is at the heart of understandi...</td>\n",
       "      <td>18</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Vincent Granville</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/light-on-math-m...</td>\n",
       "      <td>https://medium.com/@analyticbridge?source=tag_...</td>\n",
       "      <td>['Topic modelling refers to the task of identi...</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>38</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>Python()TF-IDF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Yanwei Liu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@yanweiliu/python%E8%87%AA%...</td>\n",
       "      <td>https://medium.com/@yanweiliu?source=tag_archi...</td>\n",
       "      <td>['Written by', 'Written by']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Srujitha Mudunuri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://chatbotslife.com/best-nlp-chatbot-plat...</td>\n",
       "      <td>https://medium.com/@srujitha.mudunuri?source=t...</td>\n",
       "      <td>['The future is here!', 'Technology developing...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>Quality is not an act, it is a habit.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuldeep Singh Arya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@kuldeeparya3794/quality-is...</td>\n",
       "      <td>https://medium.com/@kuldeeparya3794?source=tag...</td>\n",
       "      <td>['Written by', 'Written by']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>Are you working on Neural Machine Translation....</td>\n",
       "      <td>Please give some ideas for Neural Machine Tran...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kuldeep Singh Arya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/modern-nlp/semantic-search-...</td>\n",
       "      <td>https://medium.com/@kuldeeparya3794?source=tag...</td>\n",
       "      <td>['Make robust search engines', 'It took me a l...</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Yash Jain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/word-embedding-...</td>\n",
       "      <td>https://medium.com/@yash.jain3599?source=tag_a...</td>\n",
       "      <td>['In the world of NLP, representing words or s...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>OWL is not usually written in RDF-XML, it so h...</td>\n",
       "      <td>Today, most OWL is written in the much more re...</td>\n",
       "      <td>0</td>\n",
       "      <td>Kingsley Uyi Idehen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/neo4j-vs-grakn-...</td>\n",
       "      <td>https://medium.com/@kidehen?source=tag_archive...</td>\n",
       "      <td>['Dear readers, in this series of articles I c...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Kingsley Uyi Idehen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/neo4j-vs-grakn-...</td>\n",
       "      <td>https://medium.com/@kidehen?source=tag_archive...</td>\n",
       "      <td>['Dear readers, in this series of articles I c...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>i think its steming,not lemmatizing</td>\n",
       "      <td>i think its stemming</td>\n",
       "      <td>0</td>\n",
       "      <td>yelineedi dorayya chowdary</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/analytics-vidhya/tf-idf-ter...</td>\n",
       "      <td>https://medium.com/@sreesai5c?source=tag_archi...</td>\n",
       "      <td>['TF-IDF or ( Term Frequency(TF) â€” Inverse Den...</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>KARAN SALUJA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/text-summarizat...</td>\n",
       "      <td>https://medium.com/@karansaluja.bits?source=ta...</td>\n",
       "      <td>['With the rise of internet, we now have infor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>570</th>\n",
       "      <td>Hi Giavid Valiyev,</td>\n",
       "      <td>In any case, I wanted to shout out___ as the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>Marc TorSoc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@_init_/using-zipfs-law-to-...</td>\n",
       "      <td>https://medium.com/@mtorrellassocastro?source=...</td>\n",
       "      <td>['In this article, I will explain what is Zipf...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>Ways businesses are impacted by rpa, ocr and nlp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Mantha Anirudh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@anirudh.m/ways-businesses-...</td>\n",
       "      <td>https://medium.com/@anirudh.m?source=tag_archi...</td>\n",
       "      <td>['Written by', 'Written by']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Liu Wei</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/@liuwei_97790/how-technolog...</td>\n",
       "      <td>https://medium.com/@liuwei_97790?source=tag_ar...</td>\n",
       "      <td>['Written by', 'Written by']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Vincent Claes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/summarization-h...</td>\n",
       "      <td>https://medium.com/@vincentclaes_43752?source=...</td>\n",
       "      <td>['Have you ever had to summarize a lengthy doc...</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Awesome Kid</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/generating-text...</td>\n",
       "      <td>https://medium.com/@arjunarastogi?source=tag_a...</td>\n",
       "      <td>['There are many articles that have gained pop...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>Hello, Ibrahim.</td>\n",
       "      <td>Thanks for your article. Its so important and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Doaa mohamed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/introduction-to...</td>\n",
       "      <td>https://medium.com/@doaamohamed1995123?source=...</td>\n",
       "      <td>['NLP is an interdisciplinary field concerned ...</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Thanks for the informative article Gunjit!</td>\n",
       "      <td>https://stackoverflow.com/questions/61254065/h...</td>\n",
       "      <td>0</td>\n",
       "      <td>yonatan shalev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/voice-tech-podcast/auto-tex...</td>\n",
       "      <td>https://medium.com/@yonish3?source=tag_archive...</td>\n",
       "      <td>['Natural language processing and within this ...</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Hey thanks for putting this together! Youre do...</td>\n",
       "      <td>In the article you say that ULMFiT gets better...</td>\n",
       "      <td>0</td>\n",
       "      <td>Raj Singh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/huggingface/distilbert-8cf3...</td>\n",
       "      <td>https://medium.com/@raj.singh_51969?source=tag...</td>\n",
       "      <td>['2019, October 3rd â€” Update: We are releasing...</td>\n",
       "      <td>9</td>\n",
       "      <td>59</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>farima fatahi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/an-implementati...</td>\n",
       "      <td>https://medium.com/@farima.fatahi1374?source=t...</td>\n",
       "      <td>['Word2Vec is touted as one of the biggest, mo...</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Matt Moehr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/tim-black/fuzzy-string-matc...</td>\n",
       "      <td>https://medium.com/@mattmoehr?source=tag_archi...</td>\n",
       "      <td>['More and more often, companies are blending ...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Bin Wang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://towardsdatascience.com/named-entity-re...</td>\n",
       "      <td>https://medium.com/@binwang.cu?source=tag_arch...</td>\n",
       "      <td>['Named entity recognition (NER)is probably th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/voice-tech-global/conversat...</td>\n",
       "      <td>https://medium.com/@nick_wells?source=tag_arch...</td>\n",
       "      <td>['Podcasts have been consumed by many of us, w...</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://medium.com/@CobusGreyling/managing-use...</td>\n",
       "      <td>https://medium.com/@nick_wells?source=tag_arch...</td>\n",
       "      <td>['Most chatbot conversations follow a very sim...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title  \\\n",
       "558                                                NaN   \n",
       "559                                                NaN   \n",
       "560                                                NaN   \n",
       "561                                     Python()TF-IDF   \n",
       "562                                                NaN   \n",
       "563              Quality is not an act, it is a habit.   \n",
       "564  Are you working on Neural Machine Translation....   \n",
       "565                                                NaN   \n",
       "566  OWL is not usually written in RDF-XML, it so h...   \n",
       "567                                                NaN   \n",
       "568                i think its steming,not lemmatizing   \n",
       "569                                                NaN   \n",
       "570                                 Hi Giavid Valiyev,   \n",
       "571   Ways businesses are impacted by rpa, ocr and nlp   \n",
       "572                                                NaN   \n",
       "573                                                NaN   \n",
       "574                                                NaN   \n",
       "575                                    Hello, Ibrahim.   \n",
       "576         Thanks for the informative article Gunjit!   \n",
       "577  Hey thanks for putting this together! Youre do...   \n",
       "578                                                NaN   \n",
       "579                                                NaN   \n",
       "580                                                NaN   \n",
       "581                                                NaN   \n",
       "582                                                NaN   \n",
       "\n",
       "                                              Subtitle  Image  \\\n",
       "558                                                NaN      0   \n",
       "559                                                NaN      0   \n",
       "560                                                NaN      0   \n",
       "561                                                NaN      0   \n",
       "562                                                NaN      0   \n",
       "563                                                NaN      1   \n",
       "564  Please give some ideas for Neural Machine Tran...      0   \n",
       "565                                                NaN      0   \n",
       "566  Today, most OWL is written in the much more re...      0   \n",
       "567                                                NaN      0   \n",
       "568                               i think its stemming      0   \n",
       "569                                                NaN      0   \n",
       "570  In any case, I wanted to shout out___ as the a...      0   \n",
       "571                                                NaN      0   \n",
       "572                                                NaN      1   \n",
       "573                                                NaN      0   \n",
       "574                                                NaN      0   \n",
       "575  Thanks for your article. Its so important and ...      0   \n",
       "576  https://stackoverflow.com/questions/61254065/h...      0   \n",
       "577  In the article you say that ULMFiT gets better...      0   \n",
       "578                                                NaN      0   \n",
       "579                                                NaN      0   \n",
       "580                                                NaN      0   \n",
       "581                                                NaN      0   \n",
       "582                                                NaN      0   \n",
       "\n",
       "                         Author Publication  Year  Month  Day  Tag  \\\n",
       "558                 RAJESH SAHU         NaN  2020      1   31  NLP   \n",
       "559        Thomas Packer, Ph.D.         NaN  2020      1   31  NLP   \n",
       "560           Vincent Granville         NaN  2020      2    7  NLP   \n",
       "561                  Yanwei Liu         NaN  2020      2   11  NLP   \n",
       "562           Srujitha Mudunuri         NaN  2020      2   13  NLP   \n",
       "563          Kuldeep Singh Arya         NaN  2020      2   27  NLP   \n",
       "564          Kuldeep Singh Arya         NaN  2020      2   27  NLP   \n",
       "565                   Yash Jain         NaN  2020      3    2  NLP   \n",
       "566         Kingsley Uyi Idehen         NaN  2020      3    2  NLP   \n",
       "567         Kingsley Uyi Idehen         NaN  2020      3    2  NLP   \n",
       "568  yelineedi dorayya chowdary         NaN  2020      3   10  NLP   \n",
       "569                KARAN SALUJA         NaN  2020      3   25  NLP   \n",
       "570                 Marc TorSoc         NaN  2020      3   31  NLP   \n",
       "571              Mantha Anirudh         NaN  2020      4    3  NLP   \n",
       "572                     Liu Wei         NaN  2020      4    4  NLP   \n",
       "573               Vincent Claes         NaN  2020      4    4  NLP   \n",
       "574                 Awesome Kid         NaN  2020      4    9  NLP   \n",
       "575                Doaa mohamed         NaN  2020      4   15  NLP   \n",
       "576              yonatan shalev         NaN  2020      4   16  NLP   \n",
       "577                   Raj Singh         NaN  2020      4   18  NLP   \n",
       "578               farima fatahi         NaN  2020      4   20  NLP   \n",
       "579                  Matt Moehr         NaN  2020      4   22  NLP   \n",
       "580                    Bin Wang         NaN  2020      4   25  NLP   \n",
       "581                 Nick Saraev         NaN  2020      5    1  NLP   \n",
       "582                 Nick Saraev         NaN  2020      5    1  NLP   \n",
       "\n",
       "     Reading_Time Claps  Comment  \\\n",
       "558             0     0        1   \n",
       "559             0     0        1   \n",
       "560             0     0        1   \n",
       "561             0     0        0   \n",
       "562             0     0        1   \n",
       "563             0     0        0   \n",
       "564             0     0        1   \n",
       "565             0     0        1   \n",
       "566             0     0        1   \n",
       "567             0     0        1   \n",
       "568             0     0        1   \n",
       "569             0     0        1   \n",
       "570             0     0        1   \n",
       "571             0     0        0   \n",
       "572             0     0        0   \n",
       "573             0     0        1   \n",
       "574             0     0        1   \n",
       "575             0     0        1   \n",
       "576             0     0        1   \n",
       "577             0     0        1   \n",
       "578             0     0        1   \n",
       "579             0     0        1   \n",
       "580             0     0        1   \n",
       "581             0     0        1   \n",
       "582             0     0        1   \n",
       "\n",
       "                                                   url  \\\n",
       "558  https://medium.com/@martinpella/how-to-use-pre...   \n",
       "559  https://medium.com/modern-nlp/on-variety-of-en...   \n",
       "560  https://towardsdatascience.com/light-on-math-m...   \n",
       "561  https://medium.com/@yanweiliu/python%E8%87%AA%...   \n",
       "562  https://chatbotslife.com/best-nlp-chatbot-plat...   \n",
       "563  https://medium.com/@kuldeeparya3794/quality-is...   \n",
       "564  https://medium.com/modern-nlp/semantic-search-...   \n",
       "565  https://towardsdatascience.com/word-embedding-...   \n",
       "566  https://towardsdatascience.com/neo4j-vs-grakn-...   \n",
       "567  https://towardsdatascience.com/neo4j-vs-grakn-...   \n",
       "568  https://medium.com/analytics-vidhya/tf-idf-ter...   \n",
       "569  https://towardsdatascience.com/text-summarizat...   \n",
       "570  https://medium.com/@_init_/using-zipfs-law-to-...   \n",
       "571  https://medium.com/@anirudh.m/ways-businesses-...   \n",
       "572  https://medium.com/@liuwei_97790/how-technolog...   \n",
       "573  https://towardsdatascience.com/summarization-h...   \n",
       "574  https://towardsdatascience.com/generating-text...   \n",
       "575  https://towardsdatascience.com/introduction-to...   \n",
       "576  https://medium.com/voice-tech-podcast/auto-tex...   \n",
       "577  https://medium.com/huggingface/distilbert-8cf3...   \n",
       "578  https://towardsdatascience.com/an-implementati...   \n",
       "579  https://medium.com/tim-black/fuzzy-string-matc...   \n",
       "580  https://towardsdatascience.com/named-entity-re...   \n",
       "581  https://medium.com/voice-tech-global/conversat...   \n",
       "582  https://medium.com/@CobusGreyling/managing-use...   \n",
       "\n",
       "                                            Author_url  \\\n",
       "558  https://medium.com/@rajeshsahuise?source=tag_a...   \n",
       "559  https://medium.com/@thomaspacker?source=tag_ar...   \n",
       "560  https://medium.com/@analyticbridge?source=tag_...   \n",
       "561  https://medium.com/@yanweiliu?source=tag_archi...   \n",
       "562  https://medium.com/@srujitha.mudunuri?source=t...   \n",
       "563  https://medium.com/@kuldeeparya3794?source=tag...   \n",
       "564  https://medium.com/@kuldeeparya3794?source=tag...   \n",
       "565  https://medium.com/@yash.jain3599?source=tag_a...   \n",
       "566  https://medium.com/@kidehen?source=tag_archive...   \n",
       "567  https://medium.com/@kidehen?source=tag_archive...   \n",
       "568  https://medium.com/@sreesai5c?source=tag_archi...   \n",
       "569  https://medium.com/@karansaluja.bits?source=ta...   \n",
       "570  https://medium.com/@mtorrellassocastro?source=...   \n",
       "571  https://medium.com/@anirudh.m?source=tag_archi...   \n",
       "572  https://medium.com/@liuwei_97790?source=tag_ar...   \n",
       "573  https://medium.com/@vincentclaes_43752?source=...   \n",
       "574  https://medium.com/@arjunarastogi?source=tag_a...   \n",
       "575  https://medium.com/@doaamohamed1995123?source=...   \n",
       "576  https://medium.com/@yonish3?source=tag_archive...   \n",
       "577  https://medium.com/@raj.singh_51969?source=tag...   \n",
       "578  https://medium.com/@farima.fatahi1374?source=t...   \n",
       "579  https://medium.com/@mattmoehr?source=tag_archi...   \n",
       "580  https://medium.com/@binwang.cu?source=tag_arch...   \n",
       "581  https://medium.com/@nick_wells?source=tag_arch...   \n",
       "582  https://medium.com/@nick_wells?source=tag_arch...   \n",
       "\n",
       "                                          article_text  no_of_blockquotes  \\\n",
       "558  ['â€œFor decades, machine learning approaches ta...                  2   \n",
       "559  ['Encoding text is at the heart of understandi...                 18   \n",
       "560  ['Topic modelling refers to the task of identi...                  2   \n",
       "561                       ['Written by', 'Written by']                  0   \n",
       "562  ['The future is here!', 'Technology developing...                  5   \n",
       "563                       ['Written by', 'Written by']                  0   \n",
       "564  ['Make robust search engines', 'It took me a l...                  9   \n",
       "565  ['In the world of NLP, representing words or s...                  0   \n",
       "566  ['Dear readers, in this series of articles I c...                  0   \n",
       "567  ['Dear readers, in this series of articles I c...                  0   \n",
       "568  ['TF-IDF or ( Term Frequency(TF) â€” Inverse Den...                  7   \n",
       "569  ['With the rise of internet, we now have infor...                  0   \n",
       "570  ['In this article, I will explain what is Zipf...                  0   \n",
       "571                       ['Written by', 'Written by']                  0   \n",
       "572                       ['Written by', 'Written by']                  0   \n",
       "573  ['Have you ever had to summarize a lengthy doc...                  1   \n",
       "574  ['There are many articles that have gained pop...                  0   \n",
       "575  ['NLP is an interdisciplinary field concerned ...                  0   \n",
       "576  ['Natural language processing and within this ...                  1   \n",
       "577  ['2019, October 3rd â€” Update: We are releasing...                  9   \n",
       "578  ['Word2Vec is touted as one of the biggest, mo...                  4   \n",
       "579  ['More and more often, companies are blending ...                  0   \n",
       "580  ['Named entity recognition (NER)is probably th...                  0   \n",
       "581  ['Podcasts have been consumed by many of us, w...                  0   \n",
       "582  ['Most chatbot conversations follow a very sim...                  2   \n",
       "\n",
       "     no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "558                  0                   1                   6   \n",
       "559                 35                   2                  23   \n",
       "560                 16                  38                   9   \n",
       "561                  0                   0                   1   \n",
       "562                  7                   2                   9   \n",
       "563                  0                   0                   1   \n",
       "564                 14                   3                  14   \n",
       "565                  2                   3                   1   \n",
       "566                  3                   3                  21   \n",
       "567                  3                   3                  21   \n",
       "568                 24                  15                   9   \n",
       "569                  0                   0                   3   \n",
       "570                  1                   0                  10   \n",
       "571                  0                   0                   1   \n",
       "572                  0                   0                   1   \n",
       "573                 10                  17                   5   \n",
       "574                  4                   2                   2   \n",
       "575                 30                  26                   4   \n",
       "576                 30                   3                  19   \n",
       "577                 59                  25                  10   \n",
       "578                 28                  39                  20   \n",
       "579                  5                  16                   5   \n",
       "580                  1                   1                  19   \n",
       "581                 85                   0                  17   \n",
       "582                  3                   5                   6   \n",
       "\n",
       "     no_of_code_chunks  \n",
       "558                  1  \n",
       "559                  0  \n",
       "560                  0  \n",
       "561                  0  \n",
       "562                  0  \n",
       "563                  0  \n",
       "564                  0  \n",
       "565                  6  \n",
       "566                 17  \n",
       "567                 17  \n",
       "568                  4  \n",
       "569                  0  \n",
       "570                  0  \n",
       "571                  0  \n",
       "572                  0  \n",
       "573                  4  \n",
       "574                  1  \n",
       "575                  0  \n",
       "576                  4  \n",
       "577                  0  \n",
       "578                  2  \n",
       "579                  0  \n",
       "580                 20  \n",
       "581                  0  \n",
       "582                  0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                  76\n",
       "Subtitle              617\n",
       "Image                   0\n",
       "Author                  0\n",
       "Publication           684\n",
       "Year                    0\n",
       "Month                   0\n",
       "Day                     0\n",
       "Tag                     0\n",
       "Reading_Time            0\n",
       "Claps                   0\n",
       "Comment                 0\n",
       "url                     0\n",
       "Author_url              0\n",
       "article_text            0\n",
       "no_of_blockquotes       0\n",
       "no_of_bolded_text       0\n",
       "no_of_italics_text      0\n",
       "no_of_figures_text      0\n",
       "no_of_code_chunks       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Title'].isnull(),'Title'] = \"no title\"\n",
    "df.loc[df['Subtitle'].isnull(),'Subtitle'] = \"no subtitle\"\n",
    "df.loc[df['Publication'].isnull(),'Publication'] = \"no publication\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                 0\n",
       "Subtitle              0\n",
       "Image                 0\n",
       "Author                0\n",
       "Publication           0\n",
       "Year                  0\n",
       "Month                 0\n",
       "Day                   0\n",
       "Tag                   0\n",
       "Reading_Time          0\n",
       "Claps                 0\n",
       "Comment               0\n",
       "url                   0\n",
       "Author_url            0\n",
       "article_text          0\n",
       "no_of_blockquotes     0\n",
       "no_of_bolded_text     0\n",
       "no_of_italics_text    0\n",
       "no_of_figures_text    0\n",
       "no_of_code_chunks     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>url</th>\n",
       "      <th>Author_url</th>\n",
       "      <th>article_text</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como Machine Learning consegue diferenciar het...</td>\n",
       "      <td>O Projeto de Processamento</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucas Sepeda</td>\n",
       "      <td>Turing Talks</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>7</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://medium.com/turing-talks/como-machine-l...</td>\n",
       "      <td>https://medium.com/@lucassepeda?source=tag_arc...</td>\n",
       "      <td>['Projeto desenvolvido por: Fernando Matsumoto...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brutal truths that NLP data scientists will no...</td>\n",
       "      <td>Shared by a data scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Wei Hong</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>6</td>\n",
       "      <td>1K</td>\n",
       "      <td>0</td>\n",
       "      <td>https://towardsdatascience.com/brutal-truths-t...</td>\n",
       "      <td>https://towardsdatascience.com/@lowweihong?sou...</td>\n",
       "      <td>['According to the report by Tractica, the AI-...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Como Machine Learning consegue diferenciar het...   \n",
       "1  Brutal truths that NLP data scientists will no...   \n",
       "\n",
       "                     Subtitle  Image        Author           Publication  \\\n",
       "0  O Projeto de Processamento      1  Lucas Sepeda          Turing Talks   \n",
       "1  Shared by a data scientist      1  Low Wei Hong  Towards Data Science   \n",
       "\n",
       "   Year  Month  Day  Tag  Reading_Time Claps  Comment  \\\n",
       "0  2020      4   19  NLP             7  3.1K        0   \n",
       "1  2020      1   19  NLP             6    1K        0   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://medium.com/turing-talks/como-machine-l...   \n",
       "1  https://towardsdatascience.com/brutal-truths-t...   \n",
       "\n",
       "                                          Author_url  \\\n",
       "0  https://medium.com/@lucassepeda?source=tag_arc...   \n",
       "1  https://towardsdatascience.com/@lowweihong?sou...   \n",
       "\n",
       "                                        article_text  no_of_blockquotes  \\\n",
       "0  ['Projeto desenvolvido por: Fernando Matsumoto...                  1   \n",
       "1  ['According to the report by Tractica, the AI-...                  4   \n",
       "\n",
       "   no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "0                 25                  17                  16   \n",
       "1                 10                   1                   4   \n",
       "\n",
       "   no_of_code_chunks  \n",
       "0                  0  \n",
       "1                  0  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######cleaning starts\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicate rows\n",
    "\n",
    "df = df.drop_duplicates(subset=None,keep = 'first',inplace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['url','Author_url'],inplace = False , axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_dict = {'[kK]': '*1e3', '[mM]': '*1e6', '[bB]': '*1e9', }\n",
    "df['Claps'] = df['Claps'].replace(repl_dict, regex=True).map(pd.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl = lambda x: x.replace(\"!,\\\"#%&'()*+,-./:;<=>?@[\\\\]^_`{|}~â€“\", ' ')\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Title                  object\n",
       "Subtitle               object\n",
       "Image                   int64\n",
       "Author                 object\n",
       "Publication            object\n",
       "Year                    int64\n",
       "Month                   int64\n",
       "Day                     int64\n",
       "Tag                    object\n",
       "Reading_Time            int64\n",
       "Claps                 float64\n",
       "Comment                 int64\n",
       "article_text           object\n",
       "no_of_blockquotes       int64\n",
       "no_of_bolded_text       int64\n",
       "no_of_italics_text      int64\n",
       "no_of_figures_text      int64\n",
       "no_of_code_chunks       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select_dtypes = df.select_dtypes(include='object').applymap(repl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df['article_text'][10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['article_text']=  df['article_text'].str.join('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>Claps</th>\n",
       "      <th>Comment</th>\n",
       "      <th>article_text</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Como Machine Learning consegue diferenciar het...</td>\n",
       "      <td>O Projeto de Processamento</td>\n",
       "      <td>1</td>\n",
       "      <td>Lucas Sepeda</td>\n",
       "      <td>Turing Talks</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>7</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>['Projeto desenvolvido por: Fernando Matsumoto...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brutal truths that NLP data scientists will no...</td>\n",
       "      <td>Shared by a data scientist</td>\n",
       "      <td>1</td>\n",
       "      <td>Low Wei Hong</td>\n",
       "      <td>Towards Data Science</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>NLP</td>\n",
       "      <td>6</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>['According to the report by Tractica, the AI-...</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Como Machine Learning consegue diferenciar het...   \n",
       "1  Brutal truths that NLP data scientists will no...   \n",
       "\n",
       "                     Subtitle  Image        Author           Publication  \\\n",
       "0  O Projeto de Processamento      1  Lucas Sepeda          Turing Talks   \n",
       "1  Shared by a data scientist      1  Low Wei Hong  Towards Data Science   \n",
       "\n",
       "   Year  Month  Day  Tag  Reading_Time   Claps  Comment  \\\n",
       "0  2020      4   19  NLP             7  3100.0        0   \n",
       "1  2020      1   19  NLP             6  1000.0        0   \n",
       "\n",
       "                                        article_text  no_of_blockquotes  \\\n",
       "0  ['Projeto desenvolvido por: Fernando Matsumoto...                  1   \n",
       "1  ['According to the report by Tractica, the AI-...                  4   \n",
       "\n",
       "   no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "0                 25                  17                  16   \n",
       "1                 10                   1                   4   \n",
       "\n",
       "   no_of_code_chunks  \n",
       "0                  0  \n",
       "1                  0  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/anaconda3/lib/python3.7/site-packages (from vaderSentiment) (2.23.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests->vaderSentiment) (3.0.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###sentiments on text\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer= SentimentIntensityAnalyzer()\n",
    "\n",
    "df['compound_senti'] = [analyzer.polarity_scores(v)['compound'] for v in df['article_text']]\n",
    "df['neg_senti'] = [analyzer.polarity_scores(v)['neg'] for v in df['article_text']]\n",
    "df['neu_senti'] = [analyzer.polarity_scores(v)['neu'] for v in df['article_text']]\n",
    "df['pos_senti'] = [analyzer.polarity_scores(v)['pos'] for v in df['article_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>...</th>\n",
       "      <th>article_text</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "      <th>compound_senti</th>\n",
       "      <th>neg_senti</th>\n",
       "      <th>neu_senti</th>\n",
       "      <th>pos_senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['Podcasts have been consumed by many of us, w...</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['Most chatbot conversations follow a very sim...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title     Subtitle  Image       Author     Publication  Year  Month  \\\n",
       "581  no title  no subtitle      0  Nick Saraev  no publication  2020      5   \n",
       "582  no title  no subtitle      0  Nick Saraev  no publication  2020      5   \n",
       "\n",
       "     Day  Tag  Reading_Time  ...  \\\n",
       "581    1  NLP             0  ...   \n",
       "582    1  NLP             0  ...   \n",
       "\n",
       "                                          article_text  no_of_blockquotes  \\\n",
       "581  ['Podcasts have been consumed by many of us, w...                  0   \n",
       "582  ['Most chatbot conversations follow a very sim...                  2   \n",
       "\n",
       "    no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "581                85                   0                  17   \n",
       "582                 3                   5                   6   \n",
       "\n",
       "     no_of_code_chunks  compound_senti  neg_senti  neu_senti  pos_senti  \n",
       "581                  0          0.9998      0.008      0.859      0.134  \n",
       "582                  0          0.9863      0.031      0.897      0.072  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_text = df.drop(['article_text'],inplace = False , axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Subtitle</th>\n",
       "      <th>Image</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publication</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Reading_Time</th>\n",
       "      <th>...</th>\n",
       "      <th>Comment</th>\n",
       "      <th>no_of_blockquotes</th>\n",
       "      <th>no_of_bolded_text</th>\n",
       "      <th>no_of_italics_text</th>\n",
       "      <th>no_of_figures_text</th>\n",
       "      <th>no_of_code_chunks</th>\n",
       "      <th>compound_senti</th>\n",
       "      <th>neg_senti</th>\n",
       "      <th>neu_senti</th>\n",
       "      <th>pos_senti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>farima fatahi</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>39</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Matt Moehr</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.906</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Bin Wang</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>582</th>\n",
       "      <td>no title</td>\n",
       "      <td>no subtitle</td>\n",
       "      <td>0</td>\n",
       "      <td>Nick Saraev</td>\n",
       "      <td>no publication</td>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>NLP</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.897</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Title     Subtitle  Image         Author     Publication  Year  Month  \\\n",
       "578  no title  no subtitle      0  farima fatahi  no publication  2020      4   \n",
       "579  no title  no subtitle      0     Matt Moehr  no publication  2020      4   \n",
       "580  no title  no subtitle      0       Bin Wang  no publication  2020      4   \n",
       "581  no title  no subtitle      0    Nick Saraev  no publication  2020      5   \n",
       "582  no title  no subtitle      0    Nick Saraev  no publication  2020      5   \n",
       "\n",
       "     Day  Tag  Reading_Time  ...  Comment  no_of_blockquotes  \\\n",
       "578   20  NLP             0  ...        1                  4   \n",
       "579   22  NLP             0  ...        1                  0   \n",
       "580   25  NLP             0  ...        1                  0   \n",
       "581    1  NLP             0  ...        1                  0   \n",
       "582    1  NLP             0  ...        1                  2   \n",
       "\n",
       "     no_of_bolded_text  no_of_italics_text  no_of_figures_text  \\\n",
       "578                 28                  39                  20   \n",
       "579                  5                  16                   5   \n",
       "580                  1                   1                  19   \n",
       "581                 85                   0                  17   \n",
       "582                  3                   5                   6   \n",
       "\n",
       "     no_of_code_chunks  compound_senti  neg_senti  neu_senti  pos_senti  \n",
       "578                  2          0.9925      0.026      0.917      0.057  \n",
       "579                  0          0.9980      0.009      0.906      0.086  \n",
       "580                 20          0.9699      0.023      0.910      0.067  \n",
       "581                  0          0.9998      0.008      0.859      0.134  \n",
       "582                  0          0.9863      0.031      0.897      0.072  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_no_text.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1487"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_no_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_text.to_csv('df_features.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
